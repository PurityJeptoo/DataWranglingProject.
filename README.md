# DataWranglingProject.
### The main focus of this project was to extract data from 3 sources,assess it , clean it and finally store your merged data.
*The datasets are twitter-archive-enhanced.csv file,image-predictions.tsv file and tweet_json.txt from We Rate Dogs on twitter*.
## Project Overview.
I first gathered my datasets and loaded all of them in my pandas dataframe separately.After all the dataset are gathered,I now assessed each of them to check for dirty and untidy issues.There are two ways of assessing dataset, visual assessment which done through observation and  programmatic assessment which is done through use of codes.After identifying the quality and tidy issues,I moved to data cleaning where I worked on those quality and tidy issues found in my assessment step.When performing data cleaning, I used the Define, Code, Test algorithm.Defining is whatever you are going to do,codes is the commands to execute and finally test is to see if it worked.Once finished cleaning,I stored my merged dataset.


After completing data wrangling, I performed analysis on my merged dataset to understand it better.Firstly, checked on the Dog Stages distribution and saw that pupper was dog stage with the highest count that is 207 while doggo,puppo had the lowest count with 1.With most dogs on pupper stage, I wrote a code that will show me an image of a dog in that stage.Secondly, I explored tweets and images with highest favorite count and least count, and  found out tweet_id =822872901745569793 had the highest favourite count and was also able to visualize the image of dog corresponding to that tweet_id and the image of the dog with the least likes.


Lastly, I checked on the predictions and focused more on the first prediction, where I wanted to know which prediction had the highest count.I visualized the first prediction feature, and found out that Golden Retriever had the highest count while Malamute had the lowest count.To satisfy my curiosity, I checked on a dog image that belongs to Golden Retriever breed.

